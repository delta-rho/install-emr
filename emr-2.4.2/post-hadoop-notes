# https://github.com/tesseradata/example-vast-challenge/tree/gh-pages/bootcamp
# convert to CLI?

#hadoop distcp s3n://velocity/vast-data/nf-week2.csv /user/user3/vastChallenge/data/raw/nf
## there is a stupid temp file from distcp that needs to be deleted
  
  ## need to put this in a script
  #!/bin/bash
  USER_COUNT=25
  for i in $(eval echo "{1..$USER_COUNT}")
    do
  	  sudo useradd -m bootcamp-user-$i
  	  echo "bootcamp-user-$i:bootcamp-user-$i" | sudo chpasswd
  	  echo "bootcamp-user-$i:bootcamp-user-$i" 
 	  sudo -E -u hadoop /home/hadoop/bin/hadoop fs -mkdir /user/bootcamp-user-$i

   done
  
  
  data:
wget --no-check-certificate -O nf-week2-sample.csv https://s3-us-west-2.amazonaws.com/velocity1/vast-data/nf-week2.csv


### commands I ran ###
echo "hadoop:hadoop" | sudo chpasswd
sudo -u shiny nohup shiny-server &
hadoop fs -mkdir /tmp
hadoop fs -mkdir /user/hadoop/vast/raw/nf
hadoop fs -ls /user/hadoop
wget --no-check-certificate -O nf-week2-sample.csv https://s3-us-west-2.amazonaws.com/velocity1/vast-data/nf-week2.csv
hadoop fs -put nf-week2-sample.csv /user/hadoop/vast/raw/nf
   
   
   ## command to launch cluster
./elastic-mapreduce --create --alive --name "VelocityCluster-c3.8xLarge" --enable-debugging \
--num-instances 20 --slave-instance-type c3.8xlarge --master-instance-type c3.8xlarge --ami-version "2.4.2" \
--with-termination-protection \
--key-pair Velocity-Oregon \
--log-uri s3n://velocity1/logs \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/configure-hadoop \
--args "-m,mapred.reduce.tasks.speculative.execution=false" \
--args "-m,mapred.map.tasks.speculative.execution=false" \
--args "-m,mapred.child.java.opts=-Xmx2048m" \
--args "-m,mapred.job.reuse.jvm.num.tasks=1" \
--args "-m,mapred.tasktracker.map.tasks.maximum=24" \
--args "-m,mapred.tasktracker.reduce.tasks.maximum=4" \
--args "-h,dfs.umaskmode=000" \
--args "-h,dfs.permissions=true" \
--bootstrap-action "s3://velocity1/install-preconfigure" \
--bootstrap-action "s3://velocity1/install-r" \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/run-if --args "instance.isMaster=true,s3://velocity1/install-rstudio" \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/run-if --args "instance.isMaster=true,s3://velocity1/install-shiny-server" \
--bootstrap-action "s3://velocity1/install-protobuf" \
--bootstrap-action "s3://velocity1/install-rhipe" \
--bootstrap-action "s3://velocity1/install-additional-pkgs" \
--bootstrap-action "s3://velocity1/install-post-configure" \
--script s3://velocity1/install-post-hadoop --args "1"

###
# run a script against all nodes:
###
./elastic-mapreduce -j <job id> --script s3://velocity1/<script name>

Notes from walk through
=============================
Need bigger nodes - updateAttributes takes a long time
Check on the log files as an issue?
multiple clusters?
fair scheduler?
Add more tasks to nodes?
"pull request"
Hadoop gplcompression error
