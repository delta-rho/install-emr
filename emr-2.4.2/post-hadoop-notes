# https://github.com/tesseradata/example-vast-challenge/tree/gh-pages/bootcamp
# convert to CLI?
 rhmkdir("/user/user3/vastChallenge")

 rhmkdir("/user/user3/vastChallenge/data")
 rhmkdir("/user/user3/vastChallenge/data/raw")
 rhmkdir("/user/user3/vastChallenge/data/raw/nf")

hadoop distcp s3n://velocity/vast-data/nf-week2.csv /user/user3/vastChallenge/data/raw/nf
## there is a stupid temp file from distcp that needs to be deleted

## transform error:
testing read on a subset... Error in as.POSIXlt.character(as.character(x), ...) : 
  character string is not in a standard unambiguous format
  
  ## need to put this in a script
  #!/bin/bash
  USER_COUNT=25
  for i in $(eval echo "{1..$USER_COUNT}")
    do
  	  sudo useradd -m bootcamp-user-$i
  	  echo "bootcamp-user-$i:bootcamp-user-$i" | sudo chpasswd
  	  echo "bootcamp-user-$i:bootcamp-user-$i" 
 	  sudo -E -u hadoop /home/hadoop/bin/hadoop fs -mkdir /user/bootcamp-user-$i

   done
  
  
  data:
wget --no-check-certificate -O nf-week2-sample.csv https://s3-us-west-2.amazonaws.com/velocity1/vast-data/nf-week2.csv
#wget --no-check-certificate https://s3-us-west-2.amazonaws.com/velocity1/vast-data/vastChallenge.R


sudo -u shiny nohup shiny-server &
sudo -E -u hadoop /home/hadoop/bin/
sudo -E -u hadoop /home/hadoop/bin/hadoop fs -chmod -R 777 /	
sudo -E -u hadoop /home/hadoop/bin/hadoop fs -put nf-week2.csv /data/vast/raw/nf
chmod 755 nf-week2-sample.csv
R

# cybertools not installed
# need to use updated bootscript

### commands I ran ###
   19  echo "hadoop:hadoop" | sudo chpasswd
   20  sudo -u shiny nohup shiny-server &
   21  hadoop fs -mkdir /tmp
   22  hadoop fs -mkdir /user/hadoop/vast/raw/nf
   23  hadoop fs -ls /user/hadoop
   24  wget --no-check-certificate -O nf-week2-sample.csv https://s3-us-west-2.amazonaws.com/velocity1/vast-data/nf-week2.csv
   25  hadoop fs -put nf-week2-sample.csv /user/hadoop/vast/raw/nf
   
./elastic-mapreduce --create --alive --name "VelocityCluster" --enable-debugging \
--num-instances 2 --slave-instance-type m2.xlarge --master-instance-type m3.xlarge --ami-version "2.4.2" \
--with-termination-protection \
--key-pair Velocity \
--log-uri s3n://velocity1/logs \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/configure-hadoop \
--args "-m,mapred.reduce.tasks.speculative.execution=false" \
--args "-m,mapred.map.tasks.speculative.execution=false" \
--args "-m,mapred.map.child.java.opts=-Xmx1024m" \
--args "-m,mapred.reduce.child.java.opts=-Xmx1024m" \
--args "-m,mapred.job.reuse.jvm.num.tasks=1" \
--bootstrap-action "s3://velocity1/install-preconfigure" \
--bootstrap-action "s3://velocity1/install-r" \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/run-if --args "instance.isMaster=true,s3://velocity1/install-rstudio" \
--bootstrap-action s3://elasticmapreduce/bootstrap-actions/run-if --args "instance.isMaster=true,s3://velocity1/install-shiny-server" \
--bootstrap-action "s3://velocity1/install-protobuf" \
--bootstrap-action "s3://velocity1/install-rhipe" \
--bootstrap-action "s3://velocity1/install-additional-pkgs" \
--bootstrap-action "s3://velocity1/install-post-configure"
   